Trabalharemos com dados históricos de ações. Isto é uma simulação. Realmente, nosso trabalho é descobrir como criar um objeto de ambiente em código que simule o mercado de ações em geral.

Como observação lateral, o vetor de estado pode não estar em boa escala para passar para uma rede neural. Lembre-se de que gostamos de normalizar os dados antes de passá-los para uma rede neural ou regressão linear. Você pode fazer isso como uma etapa opcional. Em seguida, entraremos em um loop que só termina quando o processo é concluído dentro do ciclo. Vamos escolher uma ação a ser executada no ambiente. Isso pode vir do nosso agente, mas esse não é um detalhe necessário neste estágio, porque estamos pensando apenas na API para o ambiente. Você poderia facilmente escolher uma ação aleatória, embora isso provavelmente leve a uma recompensa abaixo do ideal.

O próximo passo é realmente executar a ação no ambiente. Que deve retornar o próximo estado, a recompensa por chegar ao próximo estado e uma flag concluída para nos dizer se o episódio terminou ou não. Finalmente, ele retorna e um dicionário de informações que pode nos fornecer informações adicionais sobre o meio ambiente. Este não é estritamente necessário e, de fato, está vazio para muitos ambientes, mas para nós vamos preencher o dicionário de informações para nos informar o valor atual do nosso portfólio.

Isso faz parte do estado, mas pode ser calculado a partir das variáveis ​​de estado. Portanto, é mais fácil simplesmente calculá-lo dentro do ambiente e devolvê-lo junto com todo o resto. Finalmente, atribuímos a variável do dia seguinte à variável de estado no caso em que, na próxima etapa, o agente precise usar o estado para escolher uma ação, o que é bastante simples e, em geral, não importa em que ambiente esteja olhando vai ter uma API.

Assim como vimos as perguntas que realmente queremos responder agora são: qual deve ser o estado e qual deve ser a ação e qual deve ser a recompensa? A razão pela qual precisamos discutir isso é porque há um número infinito de possibilidades e complicações. Não precisamos necessariamente simplificar um pouco o problema, mas primeiro deixe-me explicar por que essa simplificação é necessária, vamos começar pelo estado.

Há muitas coisas que você poderia considerar aqui. Primeiro, você pode pensar exatamente como um problema de série temporal. Observe o padrão dos movimentos de ações no passado e, a partir disso, tome uma decisão. Essa é provavelmente a primeira coisa que você e eu faríamos quando decidirmos se vamos comprar ou vender uma ação. No entanto, há outras coisas a considerar. Também precisamos perguntar se possuímos dinheiro suficiente para comprar as ações que queremos comprar e dados os preços das ações existentes que possuo.

Vale a pena vendê-los para obter mais dinheiro para comprar uma ação diferente. Então, na verdade, isso pode se tornar um problema de decisão complexo. Vamos emprestar algumas idéias de um documento chamado Abordagem prática de aprendizado por reforço profundo para negociação de ações.

Essa abordagem usa uma técnica de aprendizado por reforço mais avançada, conhecida como DDPG (Deep Deterministic Policy Gradients). Então, aqui está como vamos representar nosso estado. Vamos registrar quantas ações que possuímos. Por exemplo, se eu estiver olhando para a Apple, Motorola e Starbucks, isso significa que possuo três ações da Apple, cinco ações da Motorola e sete ações da Starbucks. Vamos listar o preço atual das ações:
 - Apple está sendo negociada a cinquenta dólares por ação.
 - A Motorola está sendo negociada a vinte dólares por ação. 
 - E a Starbucks está sendo negociada a trinta dólares por ação. 
 Finalmente, o último valor do estado é quanto dinheiro puro temos. Isso é dinheiro que não é investido em nenhuma ação que fica lá e não gera nenhum interesse, então digamos que temos cem dólares em dinheiro, então nosso vetor de estado total será 3 5 7 50 20 30 e 100.

Vamos considerar as ações novamente se considerarmos a enorme quantidade de possibilidades e o espaço de ação seria extremamente grande para qualquer ação. Eu tenho três opções possíveis. Eu posso vender, posso comprar ou posso segurar. O que significa não fazer nada. Agora você pode pensar que três não é ruim.

Mas agora lembre-se de que temos três ações a considerar para cada uma delas. Eu posso exercer qualquer uma das três opções acima. Então, isso me dá 3^3 atos possíveis, ou vinte e sete atos. Por exemplo, meu vetor de ação pode vender vender vender, o que significa vender minhas ações da Apple, vender minhas ações da Motorola e vender minhas ações da Starbucks, ou pode ser comprar vender segurar, o que significa que as ações da Apple vendem ações da Motorola e não fazem nada com minhas ações da Starbucks; no entanto, isso ainda é não no final da história, porque isso não diz nada sobre quantas ações comprar ou vender.

Se eu possuo dez ações de uma empresa, posso vender de zero a 10 dessas ações. Felizmente, vamos simplificar um pouco esse problema. Então, aqui está como vamos tratar as ações em nosso exemplo. Vai ser extremamente simplificado se comparado ao modo como as coisas funcionam no mundo real, mas é um começo decente. Primeiro, não vamos considerar nenhum custo de transação.

Por exemplo, se você compra ações usando a plataforma de investimentos do seu banco, normalmente isso custaria cerca de dez dólares. Para nós, será zero. Então, digamos que possuímos 10 ações da Apple e decidimos vender. Isso significa que vendemos todas as 10 ações. Quando comprarmos, compraremos o maior número possível de ações para as ações que optarmos por comprar.

Agora você pode se perguntar se eu escolho várias ações para comprar e quero comprar o maior número possível, como eu posso fazer isso? Bem, é meio ambíguo. Você pode pensar que deseja escolher as ações de tal maneira que consuma tanto dinheiro quanto possível. Mas, na verdade, esse é realmente um problema difícil, conhecido como problema da mochila. Então, o que vamos fazer é adotar uma abordagem simples e gananciosa, vivida em cada ação, comprar uma ação de cada empresa e continuar fazendo isso em um ciclo até ficar sem dinheiro.

Também venderemos as ações que queremos vender antes de comprar qualquer coisa que nos deixe com mais dinheiro que possamos usar para comprar novas ações. Isso pode parecer uma abordagem muito cautelosa, mas, na verdade, isso já nos deixa com 27 ações possíveis. significa que nossa rede neural terá que aproximar 27 valores diferentes, que já são bastante grandes e, portanto, uma ação nesse ambiente não está apenas fazendo uma única negociação, mas envolverá executar todas as etapas na ordem especificada.

Finalmente, temos a recompensa. Este é simples. A recompensa será apenas a mudança no valor do nosso portfólio. Agora estamos pensando em quão bem calculamos o valor de nosso portfólio como exemplo, suponha que possuímos 10 ações da Apple 5 ações da Motorola e 3 ações da Starbucks. Os preços das ações correspondentes são de 50 dólares para a Apple, vinte dólares para a Motorola e trinta dólares para a Starbucks. Suponhamos também que temos cem dólares em dinheiro que não são investidos em nenhuma ação. Então, o valor total de nosso portfólio será dez vezes 50 mais cinco vezes 20 mais três vezes 30 mais 100.

Isso é igual a setecentos e noventa dólares em geral. Se armazenarmos as ações que possuímos em um vetor chamado S e os preços das ações correspondentes em uma matriz chamada P e armazenarmos a quantidade de dinheiro que temos em uma variável chamada C, o valor total de nosso portfólio poderá ser calculado da seguinte forma: É igual ao produto escalar de S&P mais C a recompensa, então seremos apenas a diferença entre esses dois.

Vamos recapitular os pontos importantes sobre o ambiente e sua implementação. Primeiro, nosso ambiente será um objeto que imita a API aberta do OpenGym, de modo que ele terá funções como reset e step que retornam todas as informações necessárias para implementar nosso programa de aprendizado por reforço. Em seguida, em nosso ambiente, considerará três ações: Apple, Motorola e Starbucks. Nosso estado é um vetor com três informações. Primeiro, inclui o número de ações de cada empresa que queremos considerar. Segundo, inclui o preço das ações para cada uma dessas empresas. Terceiro, inclui a quantidade de dinheiro que temos que não é investido em ações.

Em seguida, nossas ações são um subconjunto simplificado do grande número de atos que podemos executar no mundo real. Também assumimos que não há custos de transação. Simplificando, temos três opções para cada compra ou venda de ações. Adotaremos uma abordagem de tudo ou nada onde, se comprarmos, compraremos o maior número possível de ações e se vendermos, venderemos todas as ações que possuímos. E essas reações podem ser aplicadas em qualquer combinação para cada estoque que possuímos. 

Portanto, se considerarmos três ações, teremos três ações possíveis para você perceber que, mesmo com apenas três ações e um espaço de ação muito simplificado, ainda temos um número bastante grande de ações. Portanto, a codificação das ações dessa forma não será dimensionada.

Se temos muitas ações a considerar, finalmente, a recompensa é apenas a alteração no valor de nosso portfólio, das etapas anteriores para a etapa atual. O valor de nosso portfólio é apenas o preço de cada ação que possuímos. Vezes o número de ações que possuímos mais o dinheiro investido que possuímos.
