Introdução de comércio de ações de aprendizagem de reforço

Ao criar um treinamento aprendizado por reforço, as pessoas geralmente pensam sobre isso em termos de previsão do valor de uma ação, que inclui apenas a direção, como se ela vai subir ou descer.

É claro que essa informação por si só não faz nada fisicamente. Você ainda precisa se sentar no seu computador e fazer uma venda. Se estamos falando sobre negociação automatizada de alta frequência, essa é uma história diferente. Mesmo assim, digamos que seu modelo preveja que as ações que você está vendo aumentem amanhã. Mas e se você estiver ocupado e esquecer?

Ou, e se você acredita que vai subir apenas um pouco e depois diminuir rapidamente, provavelmente você não deseja comprar essas ações. Na verdade, ele não executa nenhuma ação com base nessa previsão. Posso prever o preço das ações de amanhã, mas ainda tenho que escolher se vou agir com base nessas informações ou não. O aprendizado por reforço, por outro lado, não apenas faz previsões, mas também executa ações no ambiente que você fornece.

Vamos examinar um esboço de como isso vai funcionar. Atualmente, você provavelmente pensa nos preços das ações como um simples conjunto de dados de séries temporais. Parece mais apropriado para uma rede neural recorrente do que para o aprendizado por reforço. Então, o que torna isso um problema de aprendizado por reforço? Bem, é uma questão de perspectiva. Imagine, digamos que você esteja conectado a uma API de negociação de ações, que pode chamar funções que realizam transações financeiras no mundo real. 

Se cada ação da Google vale cinquenta dólares e compro 10 ações, significa que quinhentos dólares serão deduzidos da minha conta bancária e agora possuo 10 ações do Google, digamos que chamo a função celular e passo o argumento Apple com o número cinco. Isso significa que acabei de vender cinco ações da Apple.

Se uma ação da Apple vale trinta dólares, agora receberei 150 dólares em minha conta bancária e possuirei cinco ações a menos de ações da Apple do que antes. É importante observar que o ato de chamar essas funções é uma ação que você pode considerar em seu estado como informações como preços recentes das ações.

O ambiente é inerentemente aleatório, porque você realmente não pode prever o que acontecerá com o preço das ações de amanhã, mas seus atos afetam o meio ambiente. Em outras palavras, esses são todos os ingredientes que precisamos para especificar nosso problema como um problema de aprendizado por reforço. O nosso estado é composto de informações sobre várias ações em nosso próprio portifólio e o ambiente é o próprio mercado de ações. A recompensa é uma função do dinheiro que ganhamos e a punição é perdemos algo útil.

Quando você está olhando para uma ação e tentando decidir se compra ou não, geralmente deseja seguir a regra: compra baixa venda alta. Então, por exemplo, aqui podemos ver uma queda no valor. Este seria um bom momento para comprar. E aqui vemos um pico. Este seria um bom momento para vender, mas somente se você precisar do dinheiro.

Espero que você esteja investindo em algo em que a tendência geral esteja sempre subindo. Portanto, se você não precisa do dinheiro, a melhor coisa a fazer é deixá-lo descansar e continuar a aumentar em valor. Obviamente, o problema é que, no mundo real, você está tentando tomar essas decisões sem conhecer o futuro. Como você sabe se o preço mais recente é um mergulho ou um pico? De fato, nós não sabems. E talvez esse seja um trabalho que resta para as máquinas.
